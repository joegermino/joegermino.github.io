---
title: "FairMOE: counterfactually-fair mixture of experts with levels of interpretability"
collection: publications
permalink: /publication/2024_FairMOE
excerpt: 'In this paper, we extend our previous work arguing that interpretability should not be viewed as a binary aspect and that, instead, it should be viewed as a continuous domain-informed notion. Building on our prior work, we leverage the well-known Mixture of Experts architecture with a counterfactual fairness module to ensure the selection of consistently <i>fair</i> experts: <b>FairMOE</b>. We expand on the previous paper with a detailed analysis on the assignment of predictions to gain more insights into the strengths and weaknesses of the individual experts.'
date: 2024-07-08
venue: 'Machine Learning'
paperurl: 'https://doi.org/10.1007/978-3-031-45275-8_23'
citation: 'Germino, Joe, Nuno Moniz, and Nitesh V. Chawla. "FairMOE: counterfactually-fair mixture of experts with levels of interpretability." <i>Machine Learning</i> (2024): 1-21.'
---
Abstract: With the rise of artificial intelligence in our everyday lives, the need for human interpretation of machine learning modelsâ€™ predictions emerges as a critical issue. Generally, interpretability is viewed as a binary notion with a performance trade-off. Either a model is fully-interpretable but lacks the ability to capture more complex patterns in the data, or it is a black box. In this paper, we argue that this view is severely limiting and that instead interpretability should be viewed as a continuous domain-informed concept. We leverage the well-known Mixture of Experts architecture with user-defined limits on non-interpretability. We extend this idea with a counterfactual fairness module to ensure the selection of consistently <i>fair</i> experts: <b>FairMOE</b>. We perform an extensive experimental evaluation with fairness-related data sets and compare our proposal against state-of-the-art methods. Our results demonstrate that FairMOE is competitive with the leading fairness-aware algorithms in both fairness and predictive measures while providing more consistent performance, competitive scalability, and, most importantly, greater interpretability.

[Download paper here](https://link.springer.com/article/10.1007/s10994-024-06583-2)

Germino, Joe, Nuno Moniz, and Nitesh V. Chawla. "FairMOE: counterfactually-fair mixture of experts with levels of interpretability." <i>Machine Learning</i> (2024): 1-21.